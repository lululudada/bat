import os
import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# ç›®æ ‡ç½‘é¡µ URL
url = "http://ludada.vip"

# æœ¬åœ°ä¿å­˜å›¾ç‰‡çš„ç›®å½•
save_dir = "downloaded_images"
os.makedirs(save_dir, exist_ok=True)  # åˆ›å»ºç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰

# å‘é€ HTTP è¯·æ±‚è·å–ç½‘é¡µå†…å®¹
response = requests.get(url)
response.raise_for_status()  # æ£€æŸ¥è¯·æ±‚æ˜¯å¦æˆåŠŸ

# ä½¿ç”¨ BeautifulSoup è§£æ HTML
soup = BeautifulSoup(response.text, 'html.parser')

# æŸ¥æ‰¾æ‰€æœ‰ <img> æ ‡ç­¾
img_tags = soup.find_all('img')

# éå†å¹¶ä¸‹è½½å›¾ç‰‡
for idx, img in enumerate(img_tags, start=1):
    img_url = img.get('src')  # è·å–å›¾ç‰‡ URL
    if not img_url:
        continue  # è·³è¿‡æ— æ•ˆçš„å›¾ç‰‡é“¾æ¥

    # å¤„ç†ç›¸å¯¹è·¯å¾„ï¼ˆå¦‚ /images/example.jpgï¼‰
    img_url = urljoin(url, img_url)

    try:
        # ä¸‹è½½å›¾ç‰‡
        img_data = requests.get(img_url, timeout=10).content
        # æå–æ–‡ä»¶åï¼ˆå¦‚ example.jpgï¼‰
        img_name = os.path.basename(img_url) or f"image_{idx}.jpg"
        save_path = os.path.join(save_dir, img_name)

        # ä¿å­˜å›¾ç‰‡åˆ°æœ¬åœ°
        with open(save_path, 'wb') as f:
            f.write(img_data)
        print(f"âœ… ä¸‹è½½æˆåŠŸ: {img_name}")
    except Exception as e:
        print(f"âŒ ä¸‹è½½å¤±è´¥: {img_url} - {e}")

print("ğŸ‰ å›¾ç‰‡çˆ¬å–å®Œæˆï¼")
